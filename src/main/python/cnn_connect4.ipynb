{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "authorship_tag": "ABX9TyNNyApJ87bR8RIBRbCqvOyC",
   "include_colab_link": true
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Dataset**\n",
    "The Dataset is uploaded as zip and needs to be extracted.\n",
    "It contains the subfolders black and white which contain moves for the respective players. The folders black and white then contain folders 1-7. Each of these folders just contains a set of positions in which the best calculated move is the column index of the parent folder.\n"
   ],
   "metadata": {
    "id": "IpQpiKanmtyJ"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# !unzip database.zip"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UxfW8BK-do2u",
    "outputId": "a7f2d1e6-e28b-48e6-d08a-dd864ad0e7e6",
    "ExecuteTime": {
     "end_time": "2023-08-01T11:32:16.272017907Z",
     "start_time": "2023-08-01T11:32:16.062597050Z"
    }
   },
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unzip:  cannot find or open /content/database.zip, /content/database.zip.zip or /content/database.zip.ZIP.\r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Connect4Database**\n",
    "The Connect4Database is an implementation of the Database object and supposed to contain the positions including the __board__, __current player__ and __target column__ for each sample."
   ],
   "metadata": {
    "id": "8-naE-bXoyeG"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class Connect4Dataset(Dataset):\n",
    "    def __init__(self, board_data, player_data, label_data, transform=None):\n",
    "        self.board_data = board_data\n",
    "        self.player_data = player_data\n",
    "        self.label_data = label_data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.board_data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        board = self.board_data[index]\n",
    "        player = self.player_data[index]\n",
    "        label = self.label_data[index]\n",
    "\n",
    "        # Apply the transform (if any) to the board\n",
    "        if self.transform is not None:\n",
    "            board = self.transform(board)\n",
    "\n",
    "        return board, player, label\n",
    "\n",
    "    def add(self, board, player, column):\n",
    "        self.board_data.append(board)\n",
    "        self.player_data.append(player)\n",
    "        self.label_data.append(column)\n"
   ],
   "metadata": {
    "id": "PR5Rd5XC9GMs",
    "ExecuteTime": {
     "end_time": "2023-08-01T11:24:36.651461464Z",
     "start_time": "2023-08-01T11:24:36.478110048Z"
    }
   },
   "execution_count": 1,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtorch\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Dataset\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mConnect4Dataset\u001B[39;00m(Dataset):\n\u001B[1;32m      4\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, board_data, player_data, label_data, transform\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'torch'"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Building the Datasets**\n",
    "The samples are read from the file system and put into an Connect4Dataset"
   ],
   "metadata": {
    "id": "fP06RjJIo1W0"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "BjtM_ml9yYw0"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "\n",
    "num_columns = 7\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((7, 6)),  # Resize the images to a consistent size (e.g., 64x64)\n",
    "    transforms.Grayscale(),       # Convert images to grayscale\n",
    "    transforms.ToTensor(),        # Convert images to PyTorch tensors\n",
    "])\n",
    "\n",
    "\n",
    "positions_white = 'connect4dataset/white'\n",
    "positions_black = 'connect4dataset/black'\n",
    "dataset_white = ImageFolder(positions_white, transform=data_transforms)\n",
    "dataset_black = ImageFolder(positions_black, transform=data_transforms)\n",
    "dataset = Connect4Dataset([], [], [])\n",
    "for i in range(len(dataset_white)):\n",
    "    board, label = dataset_white[i]\n",
    "    dataset.add(board, 1, torch.eye(num_columns)[label - 1])\n",
    "for i in range(len(dataset_black)):\n",
    "    board, label = dataset_black[i]\n",
    "    dataset.add(board, 0, torch.eye(num_columns)[label - 1])\n",
    "\n",
    "train_size = int(0.6 * len(dataset))  # 60% for training\n",
    "test_size = int(0.2 * len(dataset))  # 20% for testing\n",
    "val_size = len(dataset) - train_size - test_size  # 20% for validation\n",
    "train_dataset, test_dataset, validation_dataset = torch.utils.data.random_split(dataset, [train_size, test_size, val_size])\n",
    "\n",
    "# Create data loaders for training and testing\n",
    "batch_size = 32\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Model**\n",
    "As model we use a CNN. It operates on the image of the board and stacks mulitple convolutional layers together to enable Pattern recognition.\n",
    "It is then followed by a four layer dense neural network. The first vector of the dense neural network also receives the current player as second input. The produced output vector has length 7. It contains the estimated probabilites of putting the next token in the respective column being the best move."
   ],
   "metadata": {
    "id": "NSA3xb--nSkt"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Bot(torch.nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(Bot, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 55, (2, 2))\n",
    "        #self.pool1 = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(55, 1000, (2, 2))\n",
    "        #self.pool2 = nn.MaxPool2d(2, 2)\n",
    "        self.conv3 = nn.Conv2d(1000, 1000, (2, 2))\n",
    "        #self.pool3 = nn.MaxPool2d(2, 2)\n",
    "        self.conv4 = nn.Conv2d(1000, 1000, (2, 2))\n",
    "        #self.pool4 = nn.MaxPool2d(2, 2)\n",
    "        self.fc1 = nn.Linear(3 * 2 * 1000 + 1, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 7)\n",
    "        print(self)\n",
    "\n",
    "    def forward(self, board, current_player):\n",
    "        x = F.relu(self.conv1(board))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = torch.flatten(x, 1)\n",
    "        current_player = current_player.unsqueeze(1)\n",
    "        x = torch.cat((x, current_player), dim=1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "bot = Bot()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DHU1K_Qc0b8j",
    "outputId": "b509b09d-1633-4623-cf95-92d9dd6dcdd9"
   },
   "execution_count": 84,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Bot(\n",
      "  (conv1): Conv2d(1, 55, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (conv2): Conv2d(55, 1000, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (conv3): Conv2d(1000, 1000, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (conv4): Conv2d(1000, 1000, kernel_size=(2, 2), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=6001, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=7, bias=True)\n",
      ")\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Training the model**\n",
    "As loss function we use CrossEntropy and as Optimizer SGD."
   ],
   "metadata": {
    "id": "E_bOO2gapGdP"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "binary_cross_entropy = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.SGD(bot.parameters(), lr=0.01)\n",
    "\n",
    "num_epochs = 10  # Number of training epochs\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for i, (board, current_player, label) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = bot(board, current_player)\n",
    "        loss = binary_cross_entropy(outputs, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Print the average loss every 1000 mini-batches\n",
    "        if i % 1000 == 999:\n",
    "            print(f\"[Epoch {epoch + 1}, Batch {i + 1}] Loss: {running_loss / 1000:.3f}\")\n",
    "            running_loss = 0.0\n",
    "\n",
    "print(\"Training completed.\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4C19en_fp0wl",
    "outputId": "5fb9047d-d21c-46f4-d0e2-8ab00dae341d"
   },
   "execution_count": 85,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training completed.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## **Testing the model**\n",
    "We give the model the test subset and calculate the accuracy.\n"
   ],
   "metadata": {
    "id": "Z09qSt_JrimV"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "bot.eval()  # Set the model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for board, current_player, label in test_loader:\n",
    "        outputs = bot(board, current_player)\n",
    "        predicted_indices = torch.argmax(outputs, dim=1)\n",
    "        labeled_indices = torch.argmax(label, dim=1)\n",
    "        total += label.size(0)\n",
    "        correct += (predicted_indices == labeled_indices).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Accuracy on the test set: {accuracy:.2f}%\")\n",
    "\n",
    "bot.eval()  # Set the model to evaluation mode\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for board, current_player, label in train_loader:\n",
    "        outputs = bot(board, current_player)\n",
    "        predicted_indices = torch.argmax(outputs, dim=1)\n",
    "        labeled_indices = torch.argmax(label, dim=1)\n",
    "        total += label.size(0)\n",
    "        correct += (predicted_indices == labeled_indices).sum().item()\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Accuracy on the training set: {accuracy:.2f}%\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "654KP70Ur616",
    "outputId": "8d256503-0ffa-4b3f-8d70-1992e723aa38"
   },
   "execution_count": 86,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy on the test set: 13.33%\n",
      "Accuracy on the train set: 13.72%\n"
     ]
    }
   ]
  }
 ]
}
